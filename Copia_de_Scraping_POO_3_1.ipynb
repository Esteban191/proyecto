{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMc4Hc5YOG6s"
      },
      "source": [
        "# **Scraping**\n",
        "## imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "R_Rls_cKvw2y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87486c63-24d9-4d61-c309-4eb3b0ca287d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QqNEjNdqOG6w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e01a9652-506c-48cf-a110-398039d2ebb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [1 InRelease 0 B/3,626 B 0%] [Co\u001b[0m\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcont\u001b[0m\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [517 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.0 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,144 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,264 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,016 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,165 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,287 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [49.9 kB]\n",
            "Hit:18 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 6,829 kB in 2s (3,566 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "18 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.13.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.4)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.22.2-py3-none-any.whl (400 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.2/400.2 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.4)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.1.3)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed h11-0.14.0 outcome-1.2.0 selenium-4.13.0 trio-0.22.2 trio-websocket-0.11.1 wsproto-1.2.0\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.1.5-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.0/154.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.1.5\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement chromium-chromedriver (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for chromium-chromedriver\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (2023.3.post1)\n"
          ]
        }
      ],
      "source": [
        "!apt update\n",
        "!pip install selenium\n",
        "!pip install openpyxl\n",
        "!pip install xlsxwriter\n",
        "!pip install chromium-chromedriver\n",
        "!pip install pytz\n",
        "\n",
        "from datetime import datetime\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "import re\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "driver = webdriver.Chrome(options=options)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFAx2RphOG6y"
      },
      "source": [
        "## Extraccion de datos\n",
        "- equipos -> [[equipos_locales], [equipos_visitantes]]\n",
        "- cuotas -> [[cuota_local, cuota_empate, cuota_visitante]]\n",
        "- fecha_hora -> [fecha, hora]\n",
        "- dobles oportunidades -> [[Lo/Em, Lo/Vi, Vi/Em]]\n",
        "- ambos_anotan -> [[si, no]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "XqmYt-2qOG6z"
      },
      "outputs": [],
      "source": [
        "class Scraping:\n",
        "    def __init__(self, url) -> None:\n",
        "        print(f\"analizando >> {url} <<\")\n",
        "        page = requests.get(url)\n",
        "        soup = BeautifulSoup(page.content, 'lxml')\n",
        "        self.container = soup.find('div', class_='fragment expander coupon-for-type')\n",
        "\n",
        "        duplicade_links = [elem.get(\"href\") for elem in self.container.find_all('a', title=\"Número de mercados\")]\n",
        "        self.links_per_match = []\n",
        "\n",
        "        for item in duplicade_links:\n",
        "            if item not in self.links_per_match:\n",
        "                self.links_per_match.append(item)\n",
        "\n",
        "        #variable para la liga\n",
        "        self.liga = url.split('/')[-1]\n",
        "\n",
        "    def equipos(self):\n",
        "        local_vist = []\n",
        "        for link in self.links_per_match:\n",
        "            new_url = \"https://apuestas.wplay.co\" + link\n",
        "            driver.get(new_url)\n",
        "            time.sleep(6)\n",
        "            names = driver.find_elements(By.CLASS_NAME, \"sr-lmt-plus-scb__team-name\")\n",
        "            local_vist.append([names[0].text, names[1].text])\n",
        "        return local_vist\n",
        "\n",
        "    def cuotas(self):\n",
        "        puntos = [elem.text for elem in self.container.find_all('span', class_='price dec')]\n",
        "        cuotas = [puntos[i:i+3] for i in range(0, len(puntos), 3)]\n",
        "        for i in range(len(cuotas)):\n",
        "            for j in range(len(cuotas[i])):\n",
        "                val = cuotas[i][j]\n",
        "                val = val.replace('.',',')\n",
        "                cuotas[i][j] = val\n",
        "        return cuotas\n",
        "\n",
        "    def hora_fecha(self):\n",
        "        meses = {'Ene': '01', 'Feb': '02', 'Mar': '03', 'Abr': '04', 'May': '05', 'Jun': '06',\n",
        "             'Jul': '07', 'Ago': '08', 'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dic': '12'}\n",
        "        horarios = []\n",
        "        eventos = self.container.find_all('div', {'class': 'ev'})\n",
        "        for evento in eventos:\n",
        "            hora_element = evento.find('span', {'class': 'time'})\n",
        "            fecha_element = evento.find('span', {'class': 'date'})\n",
        "\n",
        "            if hora_element and fecha_element:\n",
        "                hora = hora_element.text\n",
        "                fecha = fecha_element.text\n",
        "                fecha = fecha + ' 2023'\n",
        "                fecha = fecha.replace(fecha.split()[1], meses[fecha.split()[1]])\n",
        "                fecha_hora = fecha + ' ' + hora\n",
        "                fecha_hora = datetime.strptime(fecha_hora, '%d %m %Y %H:%M')\n",
        "                fecha_hora = datetime.strftime(fecha_hora, '%Y-%m-%d %H:%M')\n",
        "                horarios.append(str(fecha_hora).split(' '))\n",
        "        return horarios\n",
        "\n",
        "    def dobles_oportunidades(self):\n",
        "        dobles_oportunidades = []\n",
        "        for link in self.links_per_match:\n",
        "            try:\n",
        "                new_url = \"https://apuestas.wplay.co\" + link\n",
        "                new_page = requests.get(new_url)\n",
        "                new_soup = BeautifulSoup(new_page.content, 'lxml')\n",
        "                new_container = new_soup.find('ul', class_='default mkt_content limited mkt-sort-DBLC ev-sort-MT')\n",
        "                group = [elem.text for elem in new_container.find_all('span', class_=\"price dec\")]\n",
        "                #remplazando . por ,\n",
        "                for i in range(len(group)):\n",
        "                    val = group[i].replace('.',',')\n",
        "                    group[i] = val\n",
        "                dobles_oportunidades.append(group)\n",
        "            except AttributeError:\n",
        "                print(f\".  el link: -- {new_url} -- no contiene dobles_oportunidades\")\n",
        "                dobles_oportunidades.append([\"N/A\",\"N/A\", \"N/A\"])\n",
        "        return dobles_oportunidades\n",
        "\n",
        "    def ambos_anotan(self):\n",
        "        si_no = []\n",
        "        for link in self.links_per_match:\n",
        "            try:\n",
        "                new_url = \"https://apuestas.wplay.co\" + link\n",
        "                new_page = requests.get(new_url)\n",
        "                new_soup = BeautifulSoup(new_page.content, 'lxml')\n",
        "                new_container = new_soup.find('table', class_='horizontal mkt_content mkt-sort-BTSC')\n",
        "                group = [elem.text for elem in new_container.find_all('span', class_=\"price dec\")]\n",
        "                for i in range(len(group)):\n",
        "                    val = group[i].replace('.',',')\n",
        "                    group[i] = val\n",
        "                si_no.append(group)\n",
        "            except AttributeError:\n",
        "                print(f\".  el link: -- {new_url} -- no contiene ambos_anotan\")\n",
        "                si_no.append([\"N/A\",\"N/A\"])\n",
        "        return si_no"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-FQP6PhOG63"
      },
      "source": [
        "## Datos pre-patido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "VB3qmKiWOG64"
      },
      "outputs": [],
      "source": [
        "class Excel_pre_partido():\n",
        "    def __init__(self, urls) -> None:\n",
        "        ligas_totales = []\n",
        "        for url in urls:\n",
        "            try:\n",
        "                obj = Scraping(url)\n",
        "                equipos = obj.equipos()\n",
        "                cuotas = obj.cuotas()\n",
        "                hora_fecha = obj.hora_fecha()\n",
        "                dobles_oportunidades = obj.dobles_oportunidades()\n",
        "                si_no = obj.ambos_anotan()\n",
        "                self.liga = obj.liga\n",
        "\n",
        "                total_data = zip(equipos, cuotas, hora_fecha,\n",
        "                                dobles_oportunidades, si_no)\n",
        "                ligas_totales.extend(self.data_per_liga(total_data))\n",
        "            except AttributeError:\n",
        "                print(f\"{url} !NO tiene partidos¡\")\n",
        "\n",
        "            COLUMNS = [' ', 'liga', 'local', 'visitante', 'cuo_local', 'cuo_emp', 'cuo_vist', 'fecha', 'hora',\n",
        "                    'local_emp', 'local_vist', 'vist_emp', 'si_anotan', 'no_anotan']\n",
        "\n",
        "            self.Excel(ligas_totales, COLUMNS)\n",
        "\n",
        "\n",
        "    def data_per_liga(self, total_data):\n",
        "        partidos = []\n",
        "        for i in total_data:\n",
        "            local, vist = i[0]\n",
        "            cuo_local, cuo_emp, cuo_vist = i[1]\n",
        "            fecha, hora = i[2]\n",
        "            local_emp, local_vist, vist_emp = i[3]\n",
        "            si_anotan, no_anotan = i[4]\n",
        "\n",
        "            datos_part = (' ', self.liga, local, vist, cuo_local, cuo_emp, cuo_vist, fecha, hora,\n",
        "                          local_emp, local_vist, vist_emp, si_anotan, no_anotan)\n",
        "            partidos.append(datos_part)\n",
        "        return partidos\n",
        "\n",
        "    def Excel(self, data, columns):\n",
        "        df =pd.DataFrame(data, columns=columns)\n",
        "\n",
        "        nuevos_nombre = {\n",
        "            'vist':'visitante',\n",
        "            'cuo_local':'cuota_local',\n",
        "            'cuo_emp':'cuota_empate',\n",
        "            'cuo_vist':'cuota_visitante',\n",
        "            'local_emp':'local/empate',\n",
        "            'local_vist':'local/visitante',\n",
        "            'vist_emp':'visitante/empate'\n",
        "        }\n",
        "        df = df.rename(columns=nuevos_nombre)\n",
        "\n",
        "        columnas_ordenadas = [' ', 'liga', 'fecha', 'hora', 'local','cuota_local', 'vs',\n",
        "                              'cuota_empate','visitante','cuota_visitante','si_anotan', 'no_anotan',\n",
        "                              'local/empate', 'local/visitante', 'visitante/empate']\n",
        "        df = df.reindex(columns=columnas_ordenadas)\n",
        "\n",
        "        writer = pd.ExcelWriter('/content/drive/MyDrive/apuestas/xx-pre-completo-xx.xxam.xlsx', engine='xlsxwriter')\n",
        "        df.to_excel(writer, sheet_name='Cuotas_1', index=False)\n",
        "        writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWGpFD3qOG65"
      },
      "source": [
        "## Datos pos-partido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "UDcUR4SKOG66"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "import re\n",
        "\n",
        "class Excel_pos_partido():\n",
        "    def __init__(self, excel, urls) -> None:\n",
        "        try:\n",
        "            df = pd.read_excel(excel, engine='openpyxl')\n",
        "\n",
        "            columnas_interes = ['liga', 'hora', 'local', 'visitante', 'fecha']\n",
        "            df_interes = df[columnas_interes]\n",
        "            lista_general = []\n",
        "\n",
        "            grupos_por_liga = df_interes.groupby('liga', sort=False)\n",
        "\n",
        "            for liga, grupo in grupos_por_liga:\n",
        "                lista_liga = grupo.values.tolist()\n",
        "                lista_general.append(lista_liga)\n",
        "\n",
        "            assert len(lista_general) == len(urls)\n",
        "\n",
        "            columna_goles = []\n",
        "            for i in range(len(urls)):\n",
        "                columna_goles.extend(self.get_goles(urls[i], lista_general[i]))\n",
        "            self.made_excel(df, columna_goles)\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"El archivo '{excel}' no fue encontrado.\")\n",
        "        except AssertionError:\n",
        "            print(f\"se tienen {len(lista_general)} ligas, y {len(urls)} urls \\n ingrese el mismo numero de ligas que de Urls\")\n",
        "        #except Exception as e:\n",
        "\n",
        "         #   print(f\"Ocurrió un error al abrir el archivo de Excel: {e}\")\n",
        "\n",
        "    def get_goles(self, url, liga):\n",
        "        columna_goles = []\n",
        "        fechas = self.get_link(url, liga[0][4])\n",
        "        if fechas == 0:\n",
        "          error_row = ['N/DATA', 'N/DATA', 'N/DATA', 'N/DATA', 'X', 'N/DATA']\n",
        "          error_list = []\n",
        "          for i in range(len(liga)):\n",
        "            error_list.append(error_row)\n",
        "          return error_list\n",
        "        print(f\"analizanzo: >>{liga[0][0]}<<\")\n",
        "\n",
        "        driver = webdriver.Chrome(options=options)\n",
        "        driver.get(fechas)\n",
        "        time.sleep(10)\n",
        "        raw_rows = driver.find_elements(By.CLASS_NAME, 'cursor-pointer')\n",
        "\n",
        "        rows = []\n",
        "        for i in raw_rows:\n",
        "            if i.find_elements(By.CLASS_NAME, 'mobile-width-5.text-center'):\n",
        "                rows.append(i)\n",
        "\n",
        "        for i in range(len(liga)):\n",
        "            TEMPORAL = 0\n",
        "            _ = 0\n",
        "            for row in rows:\n",
        "                row_hora, row_local, row_visit = self.datos_per_row(row)\n",
        "\n",
        "                #hora_liga.strip() == row_hora.strip() and\n",
        "                if row_local.strip() == liga[i][2].strip() and row_visit.strip() == liga[i][3].strip():\n",
        "                    try:\n",
        "                        _ += 1\n",
        "                        goles = row.find_elements(By.CLASS_NAME, \"hidden-xs-up.visible-sm-up.no-wrap\")[1]\n",
        "                        goles = goles.get_attribute('outerHTML')\n",
        "                        soup = BeautifulSoup(goles, 'html.parser')\n",
        "                        goles = soup.get_text()\n",
        "                        value_row = self.evaluar_goles(puntuador=goles)\n",
        "                        if _ < 2:\n",
        "                          columna_goles.append(value_row)\n",
        "                        else:\n",
        "                          columna_goles[-1] = value_row\n",
        "                        continue\n",
        "\n",
        "                    except Exception as e:\n",
        "                        value_row = self.evaluar_goles(puntuador=None)\n",
        "                        if _ < 2:\n",
        "                          columna_goles.append(value_row)\n",
        "                        else:\n",
        "                          columna_goles[-1] = value_row\n",
        "                        continue\n",
        "                else:\n",
        "                    TEMPORAL += 1\n",
        "                    if TEMPORAL >= len(rows):\n",
        "                        value_row = self.evaluar_goles(puntuador=None)\n",
        "                        columna_goles.append(value_row)\n",
        "        return columna_goles\n",
        "\n",
        "#<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
        "    def evaluar_goles(self, puntuador):\n",
        "        if puntuador == None:\n",
        "            default = ['RES', \"E\", \"AM\", \"N/A\", \"X\", \"N/A\"]\n",
        "            return default\n",
        "        else:\n",
        "            goles = puntuador.split(':')\n",
        "            uno = int(goles[0])\n",
        "            dos = int(goles[1])\n",
        "            RES = lambda uno, dos: \"E\" if uno == dos else (\"GL\" if uno > dos else \"GV\")\n",
        "            E = lambda uno, dos: \"S\" if uno == dos else \"N\"\n",
        "            AM = lambda uno, dos : \"N\" if uno == 0 or dos == 0 else \"S\"\n",
        "            resultado = [RES(uno,dos), E(uno,dos), AM(uno,dos), uno, \"X\", dos]\n",
        "            return resultado\n",
        "\n",
        "    #obtiene los datos de hora, local y visitante de cada ilera\n",
        "    def datos_per_row(self, row):\n",
        "        hora_row = row.find_element(By.CLASS_NAME, 'mobile-width-5.text-center')\n",
        "        hora_row = hora_row.get_attribute('outerHTML')\n",
        "        soup = BeautifulSoup(hora_row, 'html.parser')\n",
        "        hora_row = soup.get_text()\n",
        "\n",
        "        equipos = []\n",
        "        espacios = row.find_elements(By.CLASS_NAME, \"hidden-xs-up.visible-sm-up.wrap\")\n",
        "        for i in espacios:\n",
        "            i = i.get_attribute(\"outerHTML\")\n",
        "            soup = BeautifulSoup(i, 'html.parser')\n",
        "            equipos.append(soup.get_text())\n",
        "\n",
        "        return hora_row, equipos[0], equipos[1]\n",
        "\n",
        "    def get_link(self, url, fecha):\n",
        "        page = requests.get(url)\n",
        "        soup = BeautifulSoup(page.content, 'lxml')\n",
        "        try:\n",
        "          statistics = soup.find('a', class_=\"stats\").get('href')\n",
        "\n",
        "          fecha = fecha.split('-')\n",
        "          fecha = \"-\".join(fecha[:2])\n",
        "\n",
        "          page = requests.get(statistics)\n",
        "          soup = BeautifulSoup(page.content, 'lxml')\n",
        "          fechas = soup.find('a', class_='btn btn-top-menu active').get('href').replace('headtohead', 'fixtures')\n",
        "          fechas = 'https://statistics.wplay.co' + fechas + '/month/' + fecha\n",
        "          return fechas\n",
        "        except AttributeError:\n",
        "          print(f\"  el link: {url} no tiene partidos, \\n  por lo que no se pueden acceder a sus fechas\")\n",
        "          return 0\n",
        "\n",
        "    def made_excel(self, df, goles):\n",
        "        df = df\n",
        "        nombres_columnas = ['RES', 'E', 'AM', '1', 'X', '2']\n",
        "        for i, nombre_columna in enumerate(nombres_columnas):\n",
        "            df[nombre_columna] = [item[i] for item in goles]\n",
        "        columnas_ordenadas = [' ', 'liga', 'fecha', 'hora', 'RES', 'E', 'AM', '1', 'X', '2',\n",
        "                              'local','cuota_local', 'vs',\n",
        "                              'cuota_empate','visitante','cuota_visitante','si_anotan', 'no_anotan',\n",
        "                              'local/empate', 'local/visitante', 'visitante/empate']\n",
        "        df = df.reindex(columns=columnas_ordenadas)\n",
        "\n",
        "        writer = pd.ExcelWriter('/content/drive/MyDrive/apuestas/xx-pos-completo-xx.xxam.xlsx', engine='xlsxwriter')\n",
        "        df.to_excel(writer, sheet_name='Cuotas_1', index=False)\n",
        "        writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNYHjRcAOG68"
      },
      "source": [
        "## RESULTADOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "inVBGIHaOG68"
      },
      "outputs": [],
      "source": [
        "#---ingrese los links en las listas----\n",
        "total_urls = [\n",
        "        #30sep'https://apuestas.wplay.co/es/PremierLeague',\n",
        "        'https://apuestas.wplay.co/es/t/19160/La-Liga',\n",
        "        #29sep'https://apuestas.wplay.co/es/Ligue1',\n",
        "        \"https://apuestas.wplay.co/es/ItaliaSerieA\",\n",
        "        #29sep'https://apuestas.wplay.co/es/Bundesliga',\n",
        "        #29sep'https://apuestas.wplay.co/es/t/19344/Bundesliga-2',\n",
        "        #28sep'https://apuestas.wplay.co/es/t/19211/Portugal-Primeira-Liga',\n",
        "        'https://apuestas.wplay.co/es/t/19372/B%C3%A9lgica-1ra-Divisi%C3%B3n-A',\n",
        "        'https://apuestas.wplay.co/es/t/19358/Holanda-Eredivisie',\n",
        "        #29sep'https://apuestas.wplay.co/es/t/19156/Inglaterra-Championship',\n",
        "        #29sep'https://apuestas.wplay.co/es/t/48352/Segunda',\n",
        "        #30sep'https://apuestas.wplay.co/es/t/19208/Escocia-Premiership',\n",
        "        #30sep'https://apuestas.wplay.co/es/t/19472/Noruega-Eliteserien',\n",
        "        'https://apuestas.wplay.co/es/t/19209/Grecia-Super-League',\n",
        "        'https://apuestas.wplay.co/es/MLS',\n",
        "        'https://apuestas.wplay.co/es/BrasilserieA',\n",
        "        #29sep'https://apuestas.wplay.co/es/t/19296/Argentina-Copa-de-la-Liga-Profesional',\n",
        "        #29sep'https://apuestas.wplay.co/es/PrimeraAColombia',\n",
        "        #sinfecha'https://apuestas.wplay.co/es/t/19398/Uruguay-Primera-Divisi%C3%B3n',\n",
        "        'https://apuestas.wplay.co/es/t/19359/Paraguay-Primera-Divisi%C3%B3n',\n",
        "        #29sep'https://apuestas.wplay.co/es/t/19342/Argentina-Primera-Nacional',\n",
        "        #28sep'https://apuestas.wplay.co/es/t/19393/Brasil-Serie-B',\n",
        "        #29sep'https://apuestas.wplay.co/es/t/29812/Colombia-Primera-B',\n",
        "        #29sep'https://apuestas.wplay.co/es/t/19373/Ecuador-Primera-A',\n",
        "        #28sep'https://apuestas.wplay.co/es/t/19340/Per%C3%BA-Primera-Divisi%C3%B3n',\n",
        "        #30sep'https://apuestas.wplay.co/es/t/19303/Chile-Primera-Divisi%C3%B3n',\n",
        "        #28sep'https://apuestas.wplay.co/es/LigaMX',\n",
        "        #12oct'https://apuestas.wplay.co/es/t/86772/World-Cup-2026-South-America-Qualifiers',\n",
        "        #12oct'https://apuestas.wplay.co/es/t/55650/Euro-2024-Qualifiers',\n",
        "        #12oct'https://apuestas.wplay.co/es/t/601779/Nations-League-Partidos',\n",
        "        #4oct'https://apuestas.wplay.co/es/UEFAChampionsLeague',\n",
        "        #5oct'https://apuestas.wplay.co/es/t/19162/UEFA-Liga-Europa',\n",
        "        #5oct'https://apuestas.wplay.co/es/t/413776/UEFA-Europa-Conference-League',\n",
        "        ]\n",
        "\n",
        "\n",
        "url=[ \"https://apuestas.wplay.co/es/PrimeraAColombia\",\n",
        "      \"https://apuestas.wplay.co/es/t/19342/Argentina-Primera-Nacional\",\"https://apuestas.wplay.co/es/t/29812/Colombia-Primera-B\"]\n",
        "#ingrese el nombre del excel a analizar\n",
        "excel = \"/content/drive/MyDrive/apuestas/cuotas_pre_partido_1.xlsx\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " url=[ \"https://apuestas.wplay.co/es/PrimeraAColombia\",\n",
        "      \"https://apuestas.wplay.co/es/t/19342/Argentina-Primera-Nacional\",\"https://apuestas.wplay.co/es/t/29812/Colombia-Primera-B\"]"
      ],
      "metadata": {
        "id": "z4r0uKnZQJ_v"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AzewbpMOG69"
      },
      "source": [
        "### **Excel pre partido**\n",
        "**solo recive los URLS**\n",
        "\n",
        "Esta llamada crea un excel con los partidos de las ligas que ingrese, sacando datos como:\n",
        "- liga\n",
        "- fecha, hora, local, visitante\n",
        "- cuotas\n",
        "- ambos anotan\n",
        "- Doble oportunidad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "JbMaYQbnOG6-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aa4b1eb-a6c0-4594-a95d-f14a6fee9345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "analizando >> https://apuestas.wplay.co/es/PrimeraAColombia <<\n",
            "analizando >> https://apuestas.wplay.co/es/t/19342/Argentina-Primera-Nacional <<\n",
            "analizando >> https://apuestas.wplay.co/es/t/29812/Colombia-Primera-B <<\n",
            "analizando >> https://apuestas.wplay.co/es/t/19359/Paraguay-Primera-Divisi%C3%B3n <<\n"
          ]
        }
      ],
      "source": [
        "PRE_PARTIDO = Excel_pre_partido(urls=total_urls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F_gv9NvOG6-"
      },
      "source": [
        "### **Excel pos partido**\n",
        "**recive como parametros las URLS y el EXCEL**\n",
        ">**Importante:** el numero de **urls** debe ser igual al numero de **ligas del excel**\n",
        "\n",
        "> el excel debe estar disponibe en la pestaña de **archivos**\n",
        "\n",
        "Esta llamada modifica el excel prepartido añadiendo:\n",
        "- goles (hallan jugado o no)\n",
        "- todos los datos del excel pre partdo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "AIylbw6rOG6-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd90c4cd-a5e9-4562-fab2-465982501d5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "analizanzo: >>PrimeraAColombia<<\n",
            "analizanzo: >>Argentina-Primera-Nacional<<\n",
            "analizanzo: >>Colombia-Primera-B<<\n"
          ]
        }
      ],
      "source": [
        "POS_PARTIDO = Excel_pos_partido(urls=total_urls, excel=excel)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4_wEFWJnMZiZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kFAx2RphOG6y"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}